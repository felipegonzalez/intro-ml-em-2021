# Introducción

## ¿Qué es aprendizaje de máquina (machine learning)? 


```{r, include = FALSE}
library(ggplot2)
theme_set(theme_minimal(base_size = 13))
cbb_palette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
scale_colour_discrete <- function(...) {
  scale_colour_manual(..., values = cbb_palette)
}
```

Métodos **computacionales** para **aprender de datos**  con el fin
de producir reglas para 
mejorar el **desempeño** en alguna tarea o toma de decisión. 

#### Ejemplos de tareas de aprendizaje: {-}

- Predecir si un cliente de tarjeta de crédito va a caer en impago en los próximos
tres meses.
- Reconocer palabras escritas a mano (OCR).
- Detectar llamados de ballenas en grabaciones de boyas. 
- Estimar el ingreso mensual de un hogar a partir de las características
de la vivienda, posesiones y equipamiento y localización geográfica.
- Dividir a los clientes de Netflix según sus gustos.
- Recomendar artículos a clientes de un programa de lealtad o servicio online.

Las razones usuales para intentar resolver estos problemas **computacionalmente**
son diversas:

- Quisiéramos obtener una respuesta barata, rápida, **automatizada**, y 
con suficiente precisión.
Por ejemplo, reconocer caracteres en una placa de coche de una fotografía se puede hacer por
personas, pero eso es lento y costoso. Igual oír cada segundo de grabación
de las boyas para saber si hay ballenas o no. Hacer mediciones directas
del ingreso de un hogar requiere mucho tiempo y esfuerzo.
- Quisiéramos **superar el desempeño actual** de los expertos o de reglas simples utilizando
datos: por ejemplo, en la decisión de dar o no un préstamo a un solicitante,
puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales
o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo.
- Al resolver estos problemas computacionalmente tenemos
oportunidad de aprender más del problema que nos interesa: estas
soluciones forman parte de un ciclo de **análisis de datos** donde podemos 
aprender de una forma más concentrada cuáles son
características y patrones importantes de nuestros datos.


Es posible aproximarse a todos estos problemas usando reglas (por ejemplo,
si los pixeles del centro de la imagen están vacíos, entonces es un cero, 
si el crédito total es mayor al 50\% del ingreso anual, declinar el préstamo, etc). Las razones para no tomar un enfoque de reglas
 construidas "a mano":

- Cuando conjuntos de reglas creadas a mano se desempeñan mal (por ejemplo, para otorgar créditos, reconocer caracteres, etc.)
- Reglas creadas a mano pueden ser difíciles de mantener (por ejemplo, un corrector
ortográfico), pues para problemas interesantes muchas veces se requieren grandes
cantidades de reglas. Por ejemplo: ¿qué búsquedas www se enfocan en
dar direcciones como resultados? ¿cómo filtrar comentarios no aceptables
en foros?


## Ejemplo: reglas y aprendizaje

*Lectura de un medidor mediante imágenes*. Supongamos que en
una infraestructura tenemos medidores análogos (de electricidad, gas, etc.) que no se comunican. ¿Podríamos pensar en utilizar
fotos tomadas automáticamente para medir el consumo?

Por ejemplo, consideramos el siguiente problema (tomado de [este sitio](http://raphael.candelier.fr/?blog=Image%20Moments)):

```{r, message = FALSE}
library(tidyverse)
library(imager)
# Datos: http://raphael.candelier.fr/?blog=Image%20Moments
medidor_vid <- load.video("figuras/gauge_raw.mp4", fps = 5)
```



Nótese que las imágenes y videos son matrices o arreglos de valores de pixeles, por ejemplo
estas son las dimensiones para el video y para un cuadro:

```{r}
dim(medidor_vid)
medidor <- frame(medidor_vid, 20)
dim(medidor)
```

En este caso, el video tienen 70 cuadros, y existen tres canales. 
Cada canal está representado por una matriz de 370x336 valores,
y en cada uno está un valor que representa la intensidad del pixel.

Buscámos hacer cálculos con estas matrices para extraer la información
que queremos. En este caso, construiremos estos cálculos a mano.

Primero filtramos (extraemos canal rojo, difuminamos y
aplicamos un umbral):

```{r}
medidor_1 <- medidor %>% R %>% isoblur(10)
aguja <-  medidor_1 %>% threshold("99%")
```


```{r, echo=FALSE}
layout(t(1:3))
par(mar = c(1, 1, 1, 1))
plot(medidor, axes = FALSE)
plot(medidor_1, axes = FALSE)
plot(aguja, axes = FALSE)
```

Logramos extraer la aguja, aunque hay algo de ruido adicional.
Podemos extraer las líneas que pasan por más pixeles
encendidos (transformada de Hough). Con estas líneas tenemos
calculada la orientación de la aguja:

```{r, message=FALSE}
lineas_h <- hough_line(aguja, ntheta = 500, data.frame = T)
lineas_top <- lineas_h %>% 
    arrange(desc(score)) %>% 
    top_n(5) %>% 
    select(-score)  
lineas_top
```


```{r, message=FALSE, echo=FALSE}
layout(matrix(1:4, 2))
par(mar = c(1, 1, 1, 1))
plot(medidor, axes = FALSE)
plot(medidor_1, axes = FALSE)
plot(aguja, axes = FALSE)
plot(aguja, axes = FALSE)
pwalk(lineas_top, nfline, col="red")
```

Y ahora podemos aplicar el proceso de arriba
a todas la imágenes:

```{r}
seleccionar_lineas <- function(lineas){
    lineas %>% 
      arrange(desc(score)) %>% 
      filter(rho > 0) %>% 
      top_n(5, score) %>% 
      select(-score) %>% 
      summarise(theta = 180 * mean(theta) / pi) %>% 
      pull(theta)
}

# procesar por cuadro
num_cuadros <- dim(medidor_vid)[3]

angulos <- 1:num_cuadros %>% 
    map( ~frame(medidor_vid, .x)) %>% 
    map(R) %>% map( ~ isoblur(.x, 10)) %>% 
    map( ~ threshold(.x, "98%")) %>% 
    map( ~ hough_line(.x, 100, data.frame = TRUE)) %>% 
    map_dbl(seleccionar_lineas)

angulos_tbl <- tibble(t = 1:num_cuadros, angulo = angulos)
```

```{r, eval = FALSE}
# puedes usar este código para crear un gif animado:
library(gganimate)
ggplot(angulos_tbl, aes(x = t, y = angulo)) +
    geom_line() +
    transition_reveal(t) 
```



![](https://media.giphy.com/media/S4HVNskqDGOADaeOY2/giphy.gif){width=150px}
![](https://media.giphy.com/media/hVm56lMsCDLHSsSOH0/giphy.gif){width=400px}


---

Por el contrario, en el **enfoque de aprendizaje**, comenzamos con un conjunto de datos etiquetado
(por una persona, por un método costoso, etc.), y utilizamos alguna
estructura general para aprender a producir la respuesta a partir
de las imágenes. Por ejemplo, en este caso podríamos usaruna red nueronal simple (funciona también con regresión usual) 
usando directamente como entrada los valores de los pixeles de la imagen,
*sin ningún preprocesamiento*:

```{r}
library(keras)
# usamos los tres canales de la imagen
x <- as.array(medidor_vid) %>% aperm(c(3,1,2,4))

# reordenamos
set.seed(12334)
orden <- sample(1:num_cuadros, num_cuadros)
x <- x[orden,,,,drop=FALSE]
y <- angulos[orden]
```


```{r}
# definir arquitectura
modelo_aguja <- keras_model_sequential() %>%
    layer_flatten() %>% 
    layer_dense(units = 30) %>%  
    layer_dense(units = 1)
```
Ajustamos el modelo:

```{r, message = FALSE}
# definir objetivo y optimizador
modelo_aguja %>% compile(
  loss = loss_mean_absolute_error,
  optimizer = optimizer_adam(lr = 0.0001),
  metrics = c('mean_absolute_error')
)
# Entrenar con backprop en minibatches
modelo_aguja %>% fit(
  x = x, y = y,
  batch_size = 10,
  epochs = 100,
  verbose = TRUE,
  validation_split = 0.1
)
```

Y observamos que obtenemos predicciones prometedoras:

```{r, out.width = '500px', fig.width = 6, fig.height = 4,}
preds <- predict(modelo_aguja, x)
preds_tbl <- tibble(y = y, preds = preds)
ggplot(preds_tbl, aes(x = preds, y = y)) +
  geom_point(alpha = 0.5) +
  geom_abline(colour = 'red')
```

De forma que podemos resolver este problema con algoritmos generales,
como regresión o redes neuronales, 
*sin tener que aplicar métodos sofisticados de
procesamiento de imágenes*. El enfoque de aprendizaje es particularmente
efectivo cuando hay cantidades grandes de datos poco ruidosos, y aunque
en este ejemplo los dos enfoques dan resultados razonables, 
en procesamiento de imágenes es cada vez más común usar redes neuronales
grandes para resolver este tipo de problemas.
